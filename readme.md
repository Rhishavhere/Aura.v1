# **AURA.v1**

*`Under Development`*



**AURA** (Advanced Universal Responsive Assistant) is a cutting-edge multi-modal AI voice assistant designed to provide intelligent and context-aware responses. This project represents the initial development phase of AURA, showcasing its core capabilities while laying the foundation for future expansion.

## Key Features

- **Multi-Modal Input Processing**: AURA can analyze and respond to:
  - Text prompts
  - Screenshots
  - Webcam captures
  - Clipboard content
- **Context-Aware Responses**: Utilizes visual and textual context to generate relevant responses
- **Real-Time Interaction**: Processes user inputs and provides immediate feedback
- **Privacy-First Design**: All processing is done locally with no data collection

## Current Capabilities

- **Visual Context Analysis**:
  - Screenshot interpretation
  - Webcam image processing
- **Text Processing**:
  - Clipboard content analysis
  - Voice-to-text response generation
- **Contextual Understanding**:
  - Maintains conversation history
  - Integrates multiple input sources

## Technical Specifications

- **AI Models**:
  - Gemini 1.5 Flash (Latest) for vision and function calling
  - Dolphin 2.9.4 Llama3.1 8B for text generation
- **Dependencies**:
  - Google Generative AI
  - Ollama
  - OpenCV
  - Pillow
  - Pyperclip


## Future Development

AURA is currently in active development with plans to implement:

- **Enhanced Voice Interaction**:
  - Natural voice recognition
  - Voice response generation
- **Expanded Functionality**:
  - System integration
  - Task automation
  - API connectivity
- **Advanced AI Capabilities**:
  - Real-time object recognition
  - Sentiment analysis
  - Predictive assistance

## Disclaimer

AURA is currently in development and may have limited functionality. The current implementation represents only a fraction of the intended capabilities. Users should expect significant updates and improvements in future versions.

